{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "myenv",
   "language": "python",
   "display_name": "Python (myenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package reuters to\n[nltk_data]     C:\\Users\\eogha\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package reuters is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\eogha\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from random import shuffle\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from os.path import join\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "import logging\n",
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "# import tensorflow.keras as keras\n",
    "\n",
    "\n",
    "from csv import reader\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "from nltk.corpus import reuters\n",
    "import nltk\n",
    "nltk.download('reuters')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D2V:\n",
    "\n",
    "    def __init__(self):\n",
    "        cores = multiprocessing.cpu_count()\n",
    "        self.__model = Doc2Vec(dm=0,\n",
    "                               vector_size=300,\n",
    "                               min_count=2,\n",
    "                               epochs=70,\n",
    "                               workers=cores - 1)\n",
    "\n",
    "    \n",
    "    def train(self, train_corpus):\n",
    "        self.__model.build_vocab(train_corpus)\n",
    "        self.__model.train(train_corpus, total_examples=self.__model.corpus_count, epochs=self.__model.epochs)\n",
    "        return 1\n",
    "\n",
    "    def save(self, folder_path, filename):\n",
    "        self.__model.save(join(folder_path, filename))\n",
    "\n",
    "    def load(self, folder_path, filename):\n",
    "        self.__model = Doc2Vec.load(join(folder_path, filename))\n",
    "\n",
    "    def infer_doc(self, doc):\n",
    "        return self.__model.infer_vector(doc)\n",
    "\n",
    "    def get_vector(self, id):\n",
    "        return self.__model.docvecs[id]\n",
    "\n",
    "    def get_similar(self, doc):\n",
    "        return self.__model.docvecs.most_similar([doc])\n",
    "\n",
    "    def get_doc_vec(self, identifier: str):\n",
    "        return self.__model.docvecs[identifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Reuters_test.d2v\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc2vec_model_location = \"G:/FYP_Work/doc2vec_models\"\n",
    "doc2vec_model_location = \"C:/Users/eogha/Documents/Workspace/doc2vec_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "taggedDocuments = [TaggedDocument(words=gensim.utils.simple_preprocess(remove_stopwords(reuters.raw(fileId).lower())), tags=[i]) for i, fileId in enumerate(reuters.fileids())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TaggedDocument(['japan', 'revise', 'long', 'term', 'energy', 'demand', 'downwards', 'ministry', 'international', 'trade', 'industry', 'miti', 'revise', 'long', 'term', 'energy', 'supply', 'demand', 'outlook', 'august', 'meet', 'forecast', 'downtrend', 'japanese', 'energy', 'demand', 'ministry', 'officials', 'said', 'miti', 'expected', 'lower', 'projection', 'primary', 'energy', 'supplies', 'year', 'mln', 'kilolitres', 'kl', 'mln', 'said', 'decision', 'follows', 'emergence', 'structural', 'changes', 'japanese', 'industry', 'following', 'rise', 'value', 'yen', 'decline', 'domestic', 'electric', 'power', 'demand', 'miti', 'planning', 'work', 'revised', 'energy', 'supply', 'demand', 'outlook', 'deliberations', 'committee', 'meetings', 'agency', 'natural', 'resources', 'energy', 'officials', 'said', 'said', 'miti', 'review', 'breakdown', 'energy', 'supply', 'sources', 'including', 'oil', 'nuclear', 'coal', 'natural', 'gas', 'nuclear', 'energy', 'provided', 'bulk', 'japan', 'electric', 'power', 'fiscal', 'year', 'ended', 'march', 'supplying', 'estimated', 'pct', 'kilowatt', 'hour', 'basis', 'followed', 'oil', 'pct', 'liquefied', 'natural', 'gas', 'pct', 'noted'], [2])\n"
     ]
    }
   ],
   "source": [
    "print(taggedDocuments[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v = D2V()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "result = d2v.train(taggedDocuments)\n",
    "if result == 1:\n",
    "        d2v.save(doc2vec_model_location, model_name)\n",
    "        print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_articles = [{'raw': reuters.raw(fileId), 'categories': reuters.categories(fileId)} for fileId in reuters.fileids() if fileId.startswith('training/')]\n",
    "test_articles = [{'raw': reuters.raw(fileId), 'categories': reuters.categories(fileId)} for fileId in reuters.fileids() if fileId.startswith('test/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v.load(doc2vec_model_location, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MultiLabelBinarizer()"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "labelBinarizer = MultiLabelBinarizer()\n",
    "labelBinarizer.fit([reuters.categories(fileId) for fileId in reuters.fileids()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_data Complete\n",
      "test_data Complete\n",
      "train_labels Complete\n",
      "test_labels Complete\n"
     ]
    }
   ],
   "source": [
    "train_data = [d2v.infer_doc(gensim.utils.simple_preprocess(remove_stopwords(article['raw'].lower()))) for article in train_articles]\n",
    "print(\"train_data Complete\")\n",
    "test_data = [d2v.infer_doc(gensim.utils.simple_preprocess(remove_stopwords(article['raw'].lower()))) for article in test_articles]\n",
    "print(\"test_data Complete\")\n",
    "train_labels = labelBinarizer.transform([article['categories'] for article in train_articles])\n",
    "print(\"train_labels Complete\")\n",
    "test_labels = labelBinarizer.transform([article['categories'] for article in test_articles])\n",
    "print(\"test_labels Complete\")\n",
    "train_data, test_data, train_labels, test_labels = np.asarray(train_data), np.asarray(test_data), np.asarray(train_labels), np.asarray(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_dimensions = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(7769, 300, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.reshape(train_data, (len(train_data),300,1))\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(7769, 90, 1)\n"
     ]
    }
   ],
   "source": [
    "train_labels = np.reshape(train_labels, (len(train_labels),90,1))\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.reshape(test_data, (len(test_data),300,1))\n",
    "test_labels = np.reshape(test_labels, (len(test_labels),90,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3019, 300, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.squeeze(train_labels, axis=-1)\n",
    "test_labels = tf.squeeze(test_labels, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv1d (Conv1D)              (None, 300, 32)           288       \n_________________________________________________________________\ndropout (Dropout)            (None, 300, 32)           0         \n_________________________________________________________________\ndense (Dense)                (None, 300, 512)          16896     \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 300, 32)           65568     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 300, 32)           0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 300, 256)          8448      \n_________________________________________________________________\ndense_2 (Dense)              (None, 300, 128)          32896     \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 100, 128)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 12800)             0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 90)                1152090   \n_________________________________________________________________\nactivation (Activation)      (None, 90)                0         \n=================================================================\nTotal params: 1,276,186\nTrainable params: 1,276,186\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "model_training = Sequential()\n",
    "# input_layer = keras.Input(shape=(300,1))\n",
    "model_training.add(InputLayer(input_shape=(300,1)))\n",
    "model_training.add(Conv1D(filters=32, kernel_size=8, padding='same', activation='relu'))\n",
    "model_training.add(Dropout(0.5))\n",
    "model_training.add(Dense(512))\n",
    "model_training.add(Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
    "model_training.add(Dropout(0.25))\n",
    "model_training.add(Dense(256))\n",
    "model_training.add(Dense(128))\n",
    "# model_training.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "# model_training.add(Dropout(0.2))\n",
    "# model_training.add(Dense(128)) \n",
    "model_training.add(MaxPooling1D(pool_size=3))\n",
    "# model_training.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "# model_training.add(Dropout(0.2))\n",
    "# model_training.add(MaxPooling1D(pool_size=3))\n",
    "# model_training.add(Dropout(0.2))\n",
    "# model_training.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='tanh'))\n",
    "# model_training.add(Dropout(0.2))\n",
    "# model_training.add(MaxPooling1D(pool_size=3))\n",
    "# model_training.add(Dropout(0.2))\n",
    "# model_training.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='tanh'))\n",
    "# model_training.add(Dropout(0.2))\n",
    "# model_training.add(MaxPooling1D(pool_size=3))\n",
    "# model_training.add(Dropout(0.2))\n",
    "#model.add(Dropout(0.2))\n",
    "model_training.add(Flatten())\n",
    "model_training.add(Dense(train_labels.shape[1]))\n",
    "model_training.add(Activation('sigmoid'))\n",
    "model_training.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model_training.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model_training.add(InputLayer(input_shape=(300,1)))\n",
    "# model.add(Dense(input_dim=doc2vec_dimensions,units = 90, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(1200, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(400, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(600, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(units = train_labels.shape[1], activation='sigmoid'))\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(train_data, train_labels, validation_data=(test_data, test_labels), batch_size=32, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "61/61 [==============================] - 27s 418ms/step - loss: 0.1815 - accuracy: 0.2663 - val_loss: 0.0506 - val_accuracy: 0.3587\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 25s 404ms/step - loss: 0.0468 - accuracy: 0.3843 - val_loss: 0.0459 - val_accuracy: 0.5575\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 25s 416ms/step - loss: 0.0336 - accuracy: 0.5991 - val_loss: 0.0239 - val_accuracy: 0.7691\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 25s 417ms/step - loss: 0.0167 - accuracy: 0.7814 - val_loss: 0.0208 - val_accuracy: 0.7907\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 26s 435ms/step - loss: 0.0129 - accuracy: 0.8181 - val_loss: 0.0209 - val_accuracy: 0.7917\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 25s 414ms/step - loss: 0.0111 - accuracy: 0.8311 - val_loss: 0.0200 - val_accuracy: 0.7900\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 27s 448ms/step - loss: 0.0098 - accuracy: 0.8517 - val_loss: 0.0229 - val_accuracy: 0.7996\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 28s 459ms/step - loss: 0.0090 - accuracy: 0.8523 - val_loss: 0.0204 - val_accuracy: 0.8026\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 30s 493ms/step - loss: 0.0083 - accuracy: 0.8580 - val_loss: 0.0224 - val_accuracy: 0.8052\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 28s 455ms/step - loss: 0.0077 - accuracy: 0.8670 - val_loss: 0.0210 - val_accuracy: 0.8099\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 26s 431ms/step - loss: 0.0071 - accuracy: 0.8658 - val_loss: 0.0206 - val_accuracy: 0.8079\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 27s 444ms/step - loss: 0.0064 - accuracy: 0.8770 - val_loss: 0.0227 - val_accuracy: 0.8046\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 28s 452ms/step - loss: 0.0061 - accuracy: 0.8705 - val_loss: 0.0223 - val_accuracy: 0.8066\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 32s 518ms/step - loss: 0.0058 - accuracy: 0.8795 - val_loss: 0.0216 - val_accuracy: 0.8102\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 26s 426ms/step - loss: 0.0055 - accuracy: 0.8792 - val_loss: 0.0222 - val_accuracy: 0.8042\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 27s 451ms/step - loss: 0.0049 - accuracy: 0.8881 - val_loss: 0.0222 - val_accuracy: 0.8072\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 25s 414ms/step - loss: 0.0046 - accuracy: 0.8785 - val_loss: 0.0226 - val_accuracy: 0.8102\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 24s 402ms/step - loss: 0.0047 - accuracy: 0.8914 - val_loss: 0.0218 - val_accuracy: 0.8082\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 25s 406ms/step - loss: 0.0045 - accuracy: 0.8794 - val_loss: 0.0238 - val_accuracy: 0.8066\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 25s 417ms/step - loss: 0.0043 - accuracy: 0.8902 - val_loss: 0.0236 - val_accuracy: 0.8109\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 26s 429ms/step - loss: 0.0041 - accuracy: 0.8842 - val_loss: 0.0237 - val_accuracy: 0.8152\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 27s 440ms/step - loss: 0.0041 - accuracy: 0.8887 - val_loss: 0.0236 - val_accuracy: 0.8188\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 26s 432ms/step - loss: 0.0035 - accuracy: 0.8956 - val_loss: 0.0241 - val_accuracy: 0.8112\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 26s 419ms/step - loss: 0.0036 - accuracy: 0.8977 - val_loss: 0.0252 - val_accuracy: 0.8109\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 25s 408ms/step - loss: 0.0035 - accuracy: 0.8945 - val_loss: 0.0246 - val_accuracy: 0.8122\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 26s 421ms/step - loss: 0.0035 - accuracy: 0.8891 - val_loss: 0.0242 - val_accuracy: 0.8175\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 26s 433ms/step - loss: 0.0033 - accuracy: 0.8962 - val_loss: 0.0243 - val_accuracy: 0.8148\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 26s 424ms/step - loss: 0.0033 - accuracy: 0.8942 - val_loss: 0.0263 - val_accuracy: 0.8129\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 26s 421ms/step - loss: 0.0035 - accuracy: 0.9016 - val_loss: 0.0245 - val_accuracy: 0.8135\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 26s 426ms/step - loss: 0.0028 - accuracy: 0.8950 - val_loss: 0.0260 - val_accuracy: 0.8082\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 26s 420ms/step - loss: 0.0030 - accuracy: 0.8996 - val_loss: 0.0269 - val_accuracy: 0.8076\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 26s 431ms/step - loss: 0.0030 - accuracy: 0.8931 - val_loss: 0.0268 - val_accuracy: 0.8201\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 26s 435ms/step - loss: 0.0030 - accuracy: 0.9054 - val_loss: 0.0268 - val_accuracy: 0.8211\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 27s 441ms/step - loss: 0.0029 - accuracy: 0.8947 - val_loss: 0.0274 - val_accuracy: 0.8152\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 25s 408ms/step - loss: 0.0026 - accuracy: 0.8964 - val_loss: 0.0268 - val_accuracy: 0.8142\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 26s 418ms/step - loss: 0.0027 - accuracy: 0.9047 - val_loss: 0.0267 - val_accuracy: 0.8178\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 27s 449ms/step - loss: 0.0026 - accuracy: 0.8980 - val_loss: 0.0284 - val_accuracy: 0.8208\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 24s 396ms/step - loss: 0.0025 - accuracy: 0.8993 - val_loss: 0.0271 - val_accuracy: 0.8158\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 24s 395ms/step - loss: 0.0026 - accuracy: 0.8949 - val_loss: 0.0304 - val_accuracy: 0.8235\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 25s 407ms/step - loss: 0.0026 - accuracy: 0.8980 - val_loss: 0.0276 - val_accuracy: 0.8129\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 24s 399ms/step - loss: 0.0023 - accuracy: 0.8972 - val_loss: 0.0274 - val_accuracy: 0.8158\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 24s 390ms/step - loss: 0.0023 - accuracy: 0.9027 - val_loss: 0.0293 - val_accuracy: 0.8132\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 23s 379ms/step - loss: 0.0025 - accuracy: 0.9020 - val_loss: 0.0290 - val_accuracy: 0.8241\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 24s 390ms/step - loss: 0.0023 - accuracy: 0.9052 - val_loss: 0.0280 - val_accuracy: 0.8178\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 24s 394ms/step - loss: 0.0026 - accuracy: 0.9009 - val_loss: 0.0281 - val_accuracy: 0.8138\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 27s 437ms/step - loss: 0.0023 - accuracy: 0.8998 - val_loss: 0.0293 - val_accuracy: 0.8125\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 29s 478ms/step - loss: 0.0024 - accuracy: 0.9041 - val_loss: 0.0295 - val_accuracy: 0.8105\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 27s 447ms/step - loss: 0.0021 - accuracy: 0.8999 - val_loss: 0.0281 - val_accuracy: 0.8165\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 27s 450ms/step - loss: 0.0023 - accuracy: 0.9018 - val_loss: 0.0281 - val_accuracy: 0.8145\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 25s 410ms/step - loss: 0.0021 - accuracy: 0.9028 - val_loss: 0.0290 - val_accuracy: 0.8142\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20644e1c148>"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "model_training.fit(train_data, train_labels, validation_data=(test_data, test_labels), batch_size=128, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_articles = [{'raw': reuters.raw(fileId), 'categories': reuters.categories(fileId)} for fileId in reuters.fileids() if fileId.startswith('test/')]\n",
    "test_data = [d2v.infer_doc(gensim.utils.simple_preprocess(article['raw'])) for article in test_articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.reshape(test_data, (len(test_data),300,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_training.predict(np.asarray(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[predictions<0.5] = 0\n",
    "predictions[predictions>=0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelBinarizer = MultiLabelBinarizer()\n",
    "labelBinarizer.fit([reuters.categories(fileId) for fileId in reuters.fileids()])\n",
    "predicted_labels = labelBinarizer.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "count = 0\n",
    "print(len(predicted_labels))\n",
    "for predicted_label, test_article in zip(predicted_labels, test_articles):\n",
    "    # print('title: {}'.format(test_article['raw'].splitlines()[0]))\n",
    "    # print('predicted: {} - actual: {}'.format(list(predicted_label), test_article['categories']))\n",
    "    # print('')\n",
    "    if collections.Counter(list(predicted_label)) == collections.Counter(test_article['categories']):\n",
    "        count = count + 1\n",
    "    # print(count)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count/len(predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [d2v.infer_doc(gensim.utils.simple_preprocess(article['raw'])) for article in test_articles]\n",
    "test_labels = labelBinarizer.transform([article['categories'] for article in test_articles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.reshape(test_data, (len(test_data),300,1))\n",
    "test_labels = np.reshape(test_labels, (len(test_labels),90,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "24/24 [==============================] - 3s 103ms/step - loss: 0.0290 - accuracy: 0.8142\n",
      "Score: 0.0290\n",
      "Accuracy: 0.8142\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model_training.evaluate(test_data, test_labels, batch_size=128)\n",
    "    \n",
    "print('Score: %1.4f' % loss)\n",
    "print('Accuracy: %1.4f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}