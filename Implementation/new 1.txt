import collections
count = 0
print(len(predicted_labels))
for predicted_label, test_article in zip(predicted_labels, test_articles):
    # print('title: {}'.format(test_article['raw'].splitlines()[0]))
    # print('predicted: {} - actual: {}'.format(list(predicted_label), test_article['categories']))
    # print('')
    if collections.Counter(list(predicted_label)) == collections.Counter(test_article['categories']):
        count = count + 1
    # print(count)
print(count)

print(count/len(predicted_labels))

doc2vec_model_location = "C:/Users/eogha/Documents/Workspace/doc2vec_models"

model_training = Sequential()
# input_layer = keras.Input(shape=(300,1))
model_training.add(InputLayer(input_shape=(300,1)))
model_training.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='tanh'))
model_training.add(Dropout(0.2))
model_training.add(MaxPooling1D(pool_size=3))
model_training.add(Dropout(0.2))
# model_training.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))
# model_training.add(Dropout(0.2))
# model_training.add(MaxPooling1D(pool_size=3)) // 
# model_training.add(Dropout(0.2))
# model_training.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='tanh'))
# model_training.add(Dropout(0.2))
# model_training.add(MaxPooling1D(pool_size=3))
# model_training.add(Dropout(0.2))
# model_training.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='tanh'))
# model_training.add(Dropout(0.2))
# model_training.add(MaxPooling1D(pool_size=3))
# model_training.add(Dropout(0.2))
#model.add(Dropout(0.2))
model_training.add(Flatten())
model_training.add(Dense(train_labels.shape[1]))
model_training.add(Activation('sigmoid'))
model_training.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
print(model_training.summary())