{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "myenv",
   "display_name": "Python (myenv)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package reuters to\n[nltk_data]     C:\\Users\\eogha\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package reuters is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\eogha\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from random import shuffle\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from os.path import join\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "import logging\n",
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "# import tensorflow.keras as keras\n",
    "\n",
    "\n",
    "from csv import reader\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "from nltk.corpus import reuters\n",
    "import nltk\n",
    "nltk.download('reuters')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D2V:\n",
    "\n",
    "    def __init__(self):\n",
    "        cores = multiprocessing.cpu_count()\n",
    "        self.__model = Doc2Vec(dm=1,\n",
    "                               vector_size=300,\n",
    "                               min_count=2,\n",
    "                               epochs=70,\n",
    "                               workers=cores - 1)\n",
    "\n",
    "    \n",
    "    def train(self, train_corpus):\n",
    "        self.__model.build_vocab(train_corpus)\n",
    "        self.__model.train(train_corpus, total_examples=self.__model.corpus_count, epochs=self.__model.epochs)\n",
    "        return 1\n",
    "\n",
    "    def save(self, folder_path, filename):\n",
    "        self.__model.save(join(folder_path, filename))\n",
    "\n",
    "    def load(self, folder_path, filename):\n",
    "        self.__model = Doc2Vec.load(join(folder_path, filename))\n",
    "\n",
    "    def infer_doc(self, doc):\n",
    "        return self.__model.infer_vector(doc)\n",
    "\n",
    "    def get_vector(self, id):\n",
    "        return self.__model.docvecs[id]\n",
    "\n",
    "    def get_similar(self, doc):\n",
    "        return self.__model.docvecs.most_similar([doc])\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"\n",
    "        Returns the labels of all documents within the Doc2Vec model\n",
    "        \"\"\"\n",
    "        return list(self.__model.docvecs.doctags.keys())\n",
    "\n",
    "    def get_doc_vec(self, identifier: str):\n",
    "        return self.__model.docvecs[identifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Reuters_test.d2v\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc2vec_model_location = \"G:/FYP_Work/doc2vec_models\"\n",
    "doc2vec_model_location = \"C:/Users/eogha/Documents/Workspace/doc2vec_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "taggedDocuments = [TaggedDocument(words=gensim.utils.simple_preprocess(reuters.raw(fileId)), tags=[i]) for i, fileId in enumerate(reuters.fileids())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TaggedDocument(['japan', 'to', 'revise', 'long', 'term', 'energy', 'demand', 'downwards', 'the', 'ministry', 'of', 'international', 'trade', 'and', 'industry', 'miti', 'will', 'revise', 'its', 'long', 'term', 'energy', 'supply', 'demand', 'outlook', 'by', 'august', 'to', 'meet', 'forecast', 'downtrend', 'in', 'japanese', 'energy', 'demand', 'ministry', 'officials', 'said', 'miti', 'is', 'expected', 'to', 'lower', 'the', 'projection', 'for', 'primary', 'energy', 'supplies', 'in', 'the', 'year', 'to', 'mln', 'kilolitres', 'kl', 'from', 'mln', 'they', 'said', 'the', 'decision', 'follows', 'the', 'emergence', 'of', 'structural', 'changes', 'in', 'japanese', 'industry', 'following', 'the', 'rise', 'in', 'the', 'value', 'of', 'the', 'yen', 'and', 'decline', 'in', 'domestic', 'electric', 'power', 'demand', 'miti', 'is', 'planning', 'to', 'work', 'out', 'revised', 'energy', 'supply', 'demand', 'outlook', 'through', 'deliberations', 'of', 'committee', 'meetings', 'of', 'the', 'agency', 'of', 'natural', 'resources', 'and', 'energy', 'the', 'officials', 'said', 'they', 'said', 'miti', 'will', 'also', 'review', 'the', 'breakdown', 'of', 'energy', 'supply', 'sources', 'including', 'oil', 'nuclear', 'coal', 'and', 'natural', 'gas', 'nuclear', 'energy', 'provided', 'the', 'bulk', 'of', 'japan', 'electric', 'power', 'in', 'the', 'fiscal', 'year', 'ended', 'march', 'supplying', 'an', 'estimated', 'pct', 'on', 'kilowatt', 'hour', 'basis', 'followed', 'by', 'oil', 'pct', 'and', 'liquefied', 'natural', 'gas', 'pct', 'they', 'noted'], [2])\n"
     ]
    }
   ],
   "source": [
    "print(taggedDocuments[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v = D2V()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = d2v.train(taggedDocuments)\n",
    "if result == 1:\n",
    "        d2v.save(doc2vec_model_location, model_name)\n",
    "        print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_articles = [{'raw': reuters.raw(fileId), 'categories': reuters.categories(fileId)} for fileId in reuters.fileids() if fileId.startswith('training/')]\n",
    "test_articles = [{'raw': reuters.raw(fileId), 'categories': reuters.categories(fileId)} for fileId in reuters.fileids() if fileId.startswith('test/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v.load(doc2vec_model_location, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MultiLabelBinarizer()"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "labelBinarizer = MultiLabelBinarizer()\n",
    "labelBinarizer.fit([reuters.categories(fileId) for fileId in reuters.fileids()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_data Complete\n",
      "test_data Complete\n",
      "train_labels Complete\n",
      "test_labels Complete\n"
     ]
    }
   ],
   "source": [
    "train_data = [d2v.infer_doc(gensim.utils.simple_preprocess(article['raw'])) for article in train_articles]\n",
    "print(\"train_data Complete\")\n",
    "test_data = [d2v.infer_doc(gensim.utils.simple_preprocess(article['raw'])) for article in test_articles]\n",
    "print(\"test_data Complete\")\n",
    "train_labels = labelBinarizer.transform([article['categories'] for article in train_articles])\n",
    "print(\"train_labels Complete\")\n",
    "test_labels = labelBinarizer.transform([article['categories'] for article in test_articles])\n",
    "print(\"test_labels Complete\")\n",
    "train_data, test_data, train_labels, test_labels = np.asarray(train_data), np.asarray(test_data), np.asarray(train_labels), np.asarray(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_dimensions = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(7769, 300, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.reshape(train_data, (len(train_data),300,1))\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(7769, 90, 1)\n"
     ]
    }
   ],
   "source": [
    "train_labels = np.reshape(train_labels, (len(train_labels),90,1))\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.reshape(test_data, (len(test_data),300,1))\n",
    "test_labels = np.reshape(test_labels, (len(test_labels),90,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3019, 300, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.squeeze(train_labels, axis=-1)\n",
    "test_labels = tf.squeeze(test_labels, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv1d_3 (Conv1D)            (None, 300, 32)           128       \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 300, 32)           0         \n_________________________________________________________________\nconv1d_4 (Conv1D)            (None, 300, 32)           3104      \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 300, 32)           0         \n_________________________________________________________________\nconv1d_5 (Conv1D)            (None, 300, 32)           3104      \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 300, 32)           0         \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 100, 32)           0         \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 100, 32)           0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 3200)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 90)                288090    \n_________________________________________________________________\nactivation_1 (Activation)    (None, 90)                0         \n=================================================================\nTotal params: 294,426\nTrainable params: 294,426\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "model_training = Sequential()\n",
    "# input_layer = keras.Input(shape=(300,1))\n",
    "model_training.add(InputLayer(input_shape=(300,1)))\n",
    "model_training.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='tanh'))\n",
    "model_training.add(Dropout(0.5))\n",
    "model_training.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='tanh'))\n",
    "model_training.add(Dropout(0.2))\n",
    "model_training.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='tanh'))\n",
    "model_training.add(Dropout(0.2))\n",
    "model_training.add(MaxPooling1D(pool_size=3))\n",
    "model_training.add(Dropout(0.2))\n",
    "# model_training.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "# model_training.add(Dropout(0.2))\n",
    "# model_training.add(MaxPooling1D(pool_size=3)) // \n",
    "# model_training.add(Dropout(0.2))\n",
    "# model_training.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='tanh'))\n",
    "# model_training.add(Dropout(0.2))\n",
    "# model_training.add(MaxPooling1D(pool_size=3))\n",
    "# model_training.add(Dropout(0.2))\n",
    "# model_training.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='tanh'))\n",
    "# model_training.add(Dropout(0.2))\n",
    "# model_training.add(MaxPooling1D(pool_size=3))\n",
    "# model_training.add(Dropout(0.2))\n",
    "#model.add(Dropout(0.2))\n",
    "model_training.add(Flatten())\n",
    "model_training.add(Dense(train_labels.shape[1]))\n",
    "model_training.add(Activation('sigmoid'))\n",
    "model_training.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model_training.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Dense(input_dim=doc2vec_dimensions,units = 90, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(1200, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(400, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(600, activation='relu'))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(units = train_labels.shape[1], activation='sigmoid'))\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(train_data, train_labels, validation_data=(test_data, test_labels), batch_size=32, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0926 - accuracy: 0.3707 - val_loss: 0.0440 - val_accuracy: 0.5760\n",
      "Epoch 2/50\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 0.0317 - accuracy: 0.6198 - val_loss: 0.0385 - val_accuracy: 0.6436\n",
      "Epoch 3/50\n",
      "243/243 [==============================] - 6s 27ms/step - loss: 0.0259 - accuracy: 0.6777 - val_loss: 0.0387 - val_accuracy: 0.6770\n",
      "Epoch 4/50\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 0.0221 - accuracy: 0.7150 - val_loss: 0.0406 - val_accuracy: 0.6698\n",
      "Epoch 5/50\n",
      "243/243 [==============================] - 6s 27ms/step - loss: 0.0206 - accuracy: 0.7185 - val_loss: 0.0401 - val_accuracy: 0.6814\n",
      "Epoch 6/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0186 - accuracy: 0.7531 - val_loss: 0.0397 - val_accuracy: 0.6973\n",
      "Epoch 7/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0182 - accuracy: 0.7541 - val_loss: 0.0371 - val_accuracy: 0.6979\n",
      "Epoch 8/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0167 - accuracy: 0.7645 - val_loss: 0.0434 - val_accuracy: 0.6999\n",
      "Epoch 9/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0155 - accuracy: 0.7754 - val_loss: 0.0434 - val_accuracy: 0.6982\n",
      "Epoch 10/50\n",
      "243/243 [==============================] - 6s 27ms/step - loss: 0.0155 - accuracy: 0.7744 - val_loss: 0.0426 - val_accuracy: 0.6926\n",
      "Epoch 11/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0149 - accuracy: 0.7809 - val_loss: 0.0451 - val_accuracy: 0.6959\n",
      "Epoch 12/50\n",
      "243/243 [==============================] - 6s 27ms/step - loss: 0.0143 - accuracy: 0.7925 - val_loss: 0.0485 - val_accuracy: 0.6920\n",
      "Epoch 13/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0139 - accuracy: 0.7884 - val_loss: 0.0429 - val_accuracy: 0.6929\n",
      "Epoch 14/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0129 - accuracy: 0.8127 - val_loss: 0.0410 - val_accuracy: 0.7112\n",
      "Epoch 15/50\n",
      "243/243 [==============================] - 6s 27ms/step - loss: 0.0125 - accuracy: 0.8078 - val_loss: 0.0398 - val_accuracy: 0.7132\n",
      "Epoch 16/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0125 - accuracy: 0.8105 - val_loss: 0.0398 - val_accuracy: 0.7085\n",
      "Epoch 17/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0120 - accuracy: 0.8206 - val_loss: 0.0412 - val_accuracy: 0.7102\n",
      "Epoch 18/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0120 - accuracy: 0.8102 - val_loss: 0.0413 - val_accuracy: 0.7022\n",
      "Epoch 19/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0116 - accuracy: 0.8138 - val_loss: 0.0443 - val_accuracy: 0.7105\n",
      "Epoch 20/50\n",
      "243/243 [==============================] - 6s 26ms/step - loss: 0.0115 - accuracy: 0.8180 - val_loss: 0.0458 - val_accuracy: 0.6979\n",
      "Epoch 21/50\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 0.0115 - accuracy: 0.8229 - val_loss: 0.0437 - val_accuracy: 0.6989\n",
      "Epoch 22/50\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 0.0117 - accuracy: 0.8160 - val_loss: 0.0413 - val_accuracy: 0.7098\n",
      "Epoch 23/50\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 0.0112 - accuracy: 0.8122 - val_loss: 0.0440 - val_accuracy: 0.7151\n",
      "Epoch 24/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0109 - accuracy: 0.8244 - val_loss: 0.0441 - val_accuracy: 0.7141\n",
      "Epoch 25/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0106 - accuracy: 0.8243 - val_loss: 0.0428 - val_accuracy: 0.7168\n",
      "Epoch 26/50\n",
      "243/243 [==============================] - 7s 30ms/step - loss: 0.0110 - accuracy: 0.8323 - val_loss: 0.0456 - val_accuracy: 0.7115\n",
      "Epoch 27/50\n",
      "243/243 [==============================] - 7s 29ms/step - loss: 0.0107 - accuracy: 0.8356 - val_loss: 0.0424 - val_accuracy: 0.7108\n",
      "Epoch 28/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0101 - accuracy: 0.8275 - val_loss: 0.0463 - val_accuracy: 0.7026\n",
      "Epoch 29/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0101 - accuracy: 0.8290 - val_loss: 0.0398 - val_accuracy: 0.7237\n",
      "Epoch 30/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0103 - accuracy: 0.8301 - val_loss: 0.0464 - val_accuracy: 0.7141\n",
      "Epoch 31/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0098 - accuracy: 0.8307 - val_loss: 0.0446 - val_accuracy: 0.7184\n",
      "Epoch 32/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0100 - accuracy: 0.8329 - val_loss: 0.0435 - val_accuracy: 0.7188\n",
      "Epoch 33/50\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 0.0101 - accuracy: 0.8310 - val_loss: 0.0430 - val_accuracy: 0.7231\n",
      "Epoch 34/50\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 0.0100 - accuracy: 0.8335 - val_loss: 0.0479 - val_accuracy: 0.7085\n",
      "Epoch 35/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0100 - accuracy: 0.8284 - val_loss: 0.0553 - val_accuracy: 0.6963\n",
      "Epoch 36/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0104 - accuracy: 0.8288 - val_loss: 0.0439 - val_accuracy: 0.7108\n",
      "Epoch 37/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0100 - accuracy: 0.8388 - val_loss: 0.0448 - val_accuracy: 0.7035\n",
      "Epoch 38/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0100 - accuracy: 0.8300 - val_loss: 0.0426 - val_accuracy: 0.7188\n",
      "Epoch 39/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0096 - accuracy: 0.8389 - val_loss: 0.0448 - val_accuracy: 0.7122\n",
      "Epoch 40/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0093 - accuracy: 0.8391 - val_loss: 0.0451 - val_accuracy: 0.7218\n",
      "Epoch 41/50\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 0.0096 - accuracy: 0.8341 - val_loss: 0.0454 - val_accuracy: 0.7151\n",
      "Epoch 42/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0096 - accuracy: 0.8320 - val_loss: 0.0482 - val_accuracy: 0.7188\n",
      "Epoch 43/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0094 - accuracy: 0.8362 - val_loss: 0.0446 - val_accuracy: 0.7284\n",
      "Epoch 44/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0095 - accuracy: 0.8347 - val_loss: 0.0517 - val_accuracy: 0.7194\n",
      "Epoch 45/50\n",
      "243/243 [==============================] - 7s 27ms/step - loss: 0.0096 - accuracy: 0.8355 - val_loss: 0.0466 - val_accuracy: 0.7224\n",
      "Epoch 46/50\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 0.0093 - accuracy: 0.8391 - val_loss: 0.0466 - val_accuracy: 0.7165\n",
      "Epoch 47/50\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 0.0096 - accuracy: 0.8335 - val_loss: 0.0491 - val_accuracy: 0.7039\n",
      "Epoch 48/50\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 0.0095 - accuracy: 0.8342 - val_loss: 0.0514 - val_accuracy: 0.7019\n",
      "Epoch 49/50\n",
      "243/243 [==============================] - 7s 28ms/step - loss: 0.0096 - accuracy: 0.8439 - val_loss: 0.0513 - val_accuracy: 0.6966\n",
      "Epoch 50/50\n",
      "243/243 [==============================] - 7s 30ms/step - loss: 0.0092 - accuracy: 0.8377 - val_loss: 0.0436 - val_accuracy: 0.7201\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ad19016b48>"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "model_training.fit(train_data, train_labels, validation_data=(test_data, test_labels), batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_articles = [{'raw': reuters.raw(fileId), 'categories': reuters.categories(fileId)} for fileId in reuters.fileids() if fileId.startswith('test/')]\n",
    "test_data = [d2v.infer_doc(gensim.utils.simple_preprocess(article['raw'])) for article in test_articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.reshape(test_data, (len(test_data),300,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_training.predict(np.asarray(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[predictions<0.5] = 0\n",
    "predictions[predictions>=0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelBinarizer = MultiLabelBinarizer()\n",
    "labelBinarizer.fit([reuters.categories(fileId) for fileId in reuters.fileids()])\n",
    "predicted_labels = labelBinarizer.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3019\n1425\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "count = 0\n",
    "print(len(predicted_labels))\n",
    "for predicted_label, test_article in zip(predicted_labels, test_articles):\n",
    "    # print('title: {}'.format(test_article['raw'].splitlines()[0]))\n",
    "    # print('predicted: {} - actual: {}'.format(list(predicted_label), test_article['categories']))\n",
    "    # print('')\n",
    "    if collections.Counter(list(predicted_label)) == collections.Counter(test_article['categories']):\n",
    "        count = count + 1\n",
    "    # print(count)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.4720105995362703\n"
     ]
    }
   ],
   "source": [
    "print(count/len(predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [d2v.infer_doc(gensim.utils.simple_preprocess(article['raw'])) for article in test_articles]\n",
    "test_labels = labelBinarizer.transform([article['categories'] for article in test_articles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.reshape(test_data, (len(test_data),300,1))\n",
    "test_labels = np.reshape(test_labels, (len(test_labels),90,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "24/24 [==============================] - 1s 14ms/step - loss: 0.0438 - accuracy: 0.7175\n",
      "Score: 0.0438\n",
      "Accuracy: 0.7175\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model_training.evaluate(test_data, test_labels, batch_size=128)\n",
    "    \n",
    "print('Score: %1.4f' % loss)\n",
    "print('Accuracy: %1.4f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}